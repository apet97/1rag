{"rank":1,"category":"correctness","subcategory":"cache","issue":"QueryCache.get blocks execute lines 2356-2362 outside lock causing race conditions","impact":"HIGH","effort":"MEDIUM","file":"clockify_support_cli_final.py","line":2356,"current":"Lines 2356-2362 execute after with-block closes: answer, metadata, timestamp = self.cache[key]\n        metadata_timestamp = metadata.get(\"timestamp\")","proposed":"Fix indentation to move all cache access inside with-block or use clockify_rag.caching.QueryCache","rationale":"Statements run after context manager closes, leading to race conditions and AttributeError when metadata is None in multi-threaded scenarios","implementation":"Import QueryCache from clockify_rag.caching and delete local implementation, or fix indentation and ensure metadata defaults handled","expected_gain":"Restores cache correctness and prevents runtime crashes under concurrent load","references":["tests/test_query_cache.py","clockify_rag/caching.py"]}
{"rank":2,"category":"correctness","subcategory":"retrieval","issue":"FAISS branch has orphaned max() call at line 1581 breaking control flow","impact":"HIGH","effort":"MEDIUM","file":"clockify_support_cli_final.py","line":1581,"current":"dense_computed = int(remaining_idx.size)\n            max(ANN_CANDIDATE_MIN, top_k * FAISS_CANDIDATE_MULTIPLIER)\n        )","proposed":"Remove orphaned max(...) line and closing parenthesis; ensure FAISS block logic is clean","rationale":"Orphaned statement from copy-paste error causes SyntaxError and FAISS retrieval cannot execute","implementation":"Delete lines 1581-1582, verify FAISS candidate selection logic matches clockify_rag.indexing pattern","expected_gain":"Restores ANN acceleration (~10x faster retrieval when FAISS available)","references":["clockify_rag/indexing.py"]}
{"rank":3,"category":"architecture","subcategory":"reuse","issue":"CLI reimplements caching, rate limiting, HTTP helpers instead of importing from clockify_rag","impact":"HIGH","effort":"MEDIUM","file":"clockify_support_cli_final.py","line":2164,"current":"Local class definitions for QueryCache, RateLimiter after importing them from clockify_rag.caching","proposed":"Delete duplicate class definitions and rely on clockify_rag.caching.QueryCache/RateLimiter and http_utils.get_session","rationale":"Duplication caused current regressions and increases maintenance cost; fixes diverge between implementations","implementation":"Remove custom classes at lines 2164-2467, update call sites, adjust tests to use shared implementations","expected_gain":"Eliminates divergence and cuts cache/rate-limit bugs by reusing battle-tested code","references":["clockify_rag/caching.py","clockify_rag/http_utils.py"]}
{"rank":4,"category":"testing","subcategory":"integration","issue":"No integration test covers full retrieve->pack->ask flow in CLI","impact":"HIGH","effort":"MEDIUM","file":"tests/test_retrieval.py","line":15,"current":"Tests exercise individual functions but not end-to-end CLI path","proposed":"Add test invoking clockify_support_cli_final.answer_once with in-memory fixtures, validate JSON schema","rationale":"Syntax regressions in retrieve() and QueryCache went unnoticed because CLI path untested","implementation":"Create fixture building fake index artifacts, call answer_once(..., debug=True), assert response structure","expected_gain":"Prevents future catastrophic regressions before release","references":["tests/test_answer_once_logging.py"]}
{"rank":5,"category":"correctness","subcategory":"retrieval","issue":"HNSW fallback path at line 1589 never initializes dense_scores variable","impact":"HIGH","effort":"LOW","file":"clockify_support_cli_final.py","line":1592,"current":"elif hnsw:\n        _, cand = hnsw.knn_query(...)  # dense_scores not set","proposed":"Set dense_scores = dense_scores_full[candidate_idx] after computing dense_scores_full in HNSW branch","rationale":"Later code expects dense_scores when dense_scores_full is None, causing UnboundLocalError","implementation":"After line 1595, add: dense_scores = dense_scores_full[candidate_idx]","expected_gain":"Ensures non-FAISS ANN path works and avoids runtime NameError","references":["tests/test_retrieval.py"]}
{"rank":6,"category":"correctness","subcategory":"retrieval","issue":"Linear fallback duplicates candidate_idx assignment and wastes dot product computation","impact":"MEDIUM","effort":"LOW","file":"clockify_support_cli_final.py","line":1600,"current":"Lines 1599-1604: dense_scores_full = vecs_n.dot(qv_n) then candidate_idx assigned twice, dense_scores computed again","proposed":"Compute dense_scores once, reuse array: dense_scores = dense_scores_full; candidate_idx = np.arange(n_chunks).tolist()","rationale":"Duplicate work doubles dot products and can return numpy array instead of list","implementation":"Remove duplicate assignments at lines 1602-1604, keep single computation","expected_gain":"~2x speedup on pure dense fallback and consistent return types","references":["benchmark.py"]}
{"rank":7,"category":"correctness","subcategory":"retrieval","issue":"candidate_idx_array built from list without deduplication allowing FAISS duplicates","impact":"MEDIUM","effort":"LOW","file":"clockify_support_cli_final.py","line":1611,"current":"candidate_idx_array = np.array(candidate_idx, dtype=np.int32)","proposed":"Wrap with deduplication: candidate_idx = sorted(set(int(i) for i in candidate_idx if 0 <= i < n_chunks))","rationale":"Duplicate IDs reduce diversity and break dedup heuristics in MMR/packing","implementation":"Apply np.unique or Python set to candidate_idx before numpy conversion","expected_gain":"Improves retrieval diversity and reduces redundant packing","references":["tests/test_retrieval.py"]}
{"rank":8,"category":"correctness","subcategory":"retrieval","issue":"hybrid_full else branch initializes with zeros instead of sentinel value","impact":"MEDIUM","effort":"LOW","file":"clockify_support_cli_final.py","line":1649,"current":"hybrid_full = np.zeros(len(chunks), dtype=\"float32\")","proposed":"Initialize with -inf or -1: hybrid_full = np.full(len(chunks), -1.0, dtype=\"float32\")","rationale":"Zero scores mislead downstream filters and caching heuristics; sentinel makes missing scores explicit","implementation":"Change np.zeros to np.full with negative sentinel value","expected_gain":"More accurate coverage thresholds and caching statistics","references":["clockify_support_cli_final.py"]}
{"rank":9,"category":"correctness","subcategory":"packing","issue":"pack_snippets truncation appends marker without adjusting token count","impact":"MEDIUM","effort":"LOW","file":"clockify_support_cli_final.py","line":1820,"current":"out[0] = out[0].replace(\"]\", \" [TRUNCATED]]\", 1)  # No token count update","proposed":"Recompute used token estimate after truncating first snippet to keep KPI accurate","rationale":"Token budget logging becomes inaccurate when first snippet truncated","implementation":"After truncation, recalc approx_tokens for first snippet and update `used` variable","expected_gain":"Accurate KPI reporting and downstream analytics","references":["tests/test_packer.py"]}
{"rank":10,"category":"correctness","subcategory":"sanitization","issue":"sanitize_question only checks simple substrings for prompt injection","impact":"MEDIUM","effort":"MEDIUM","file":"clockify_support_cli_final.py","line":2174,"current":"suspicious_patterns = ['<script', 'javascript:', ...] simple substring checks","proposed":"Expand detection with regex for triple-brace template injection, jailbreak phrases; log refusals","rationale":"Sophisticated prompt injections bypass simple substring matching","implementation":"Add regex list, centralize in security module with unit tests","expected_gain":"Reduces chance of prompt-injection exploitation","references":["tests/test_sanitization.py"]}
{"rank":11,"category":"performance","subcategory":"caching","issue":"Embedding cache writes entire file on every build even for few updates","impact":"MEDIUM","effort":"MEDIUM","file":"clockify_support_cli_final.py","line":1991,"current":"if cache_miss_indices:\n            save_embedding_cache(emb_cache)  # Rewrites entire cache","proposed":"Write incremental updates by appending only new entries or using SQLite backend","rationale":"Large caches rewrite MBs of data causing slow incremental builds","implementation":"Maintain append-only log or checksum to persist only new hashes","expected_gain":"30-50% faster incremental builds for large knowledge bases","references":["clockify_rag/embedding.py"]}
{"rank":12,"category":"performance","subcategory":"retrieval","issue":"DenseScoreStore always materializes full dot product when qv/vecs provided","impact":"MEDIUM","effort":"MEDIUM","file":"clockify_support_cli_final.py","line":1489,"current":"self._full = self._vecs.dot(self._qv).astype(\"float32\")  # Always computes full","proposed":"Lazily compute full array only when needed; cache dot product for requested indices","rationale":"For small top_k waste time computing full dot product for entire corpus","implementation":"Store vecs and qv, compute slice on demand using np.dot for subset","expected_gain":"Reduces latency for large corpora when only few scores needed","references":["benchmark.py"]}
{"rank":13,"category":"evaluation","subcategory":"metrics","issue":"eval.py lacks relevance metrics and depends on live Ollama service","impact":"HIGH","effort":"MEDIUM","file":"eval.py","line":210,"current":"Manual answer comparison helpers; # TODO: compute metrics","proposed":"Implement offline evaluation using stored embeddings; compute MRR/NDCG/accuracy with ground truth","rationale":"Without metrics there is no regression signal for retrieval quality improvements","implementation":"Load eval_dataset.jsonl, compare model answers to references, output metrics JSON","expected_gain":"Enables CI gating on retrieval quality and tracks improvements over time","references":["eval_dataset.jsonl","tests/test_retrieval.py"]}
{"rank":14,"category":"documentation","subcategory":"consolidation","issue":"Dozens of stale deliverable markdowns confuse onboarding and contradict each other","impact":"MEDIUM","effort":"MEDIUM","file":"README.md","line":1,"current":"Multiple conflicting readiness statements across 50+ markdown files","proposed":"Archive legacy docs into /archive folder, author single source README + operations guide","rationale":"Conflicting documentation undermines trust and slows onboarding significantly","implementation":"Create docs/ with up-to-date guides, update README links, delete/archive superseded files","expected_gain":"Cuts onboarding time and reduces compliance risk from stale instructions","references":["PROJECT_STRUCTURE.md","START_HERE.md"]}
{"rank":15,"category":"security","subcategory":"network","issue":"deepseek_ollama_shim.py allows unauthenticated access by default","impact":"MEDIUM","effort":"LOW","file":"deepseek_ollama_shim.py","line":69,"current":"if AUTH_TOKEN: ...  # Optional auth","proposed":"Require AUTH_TOKEN unless explicitly disabled via env flag; log rejected attempts","rationale":"Open shim can leak paid API key and expose embeddings endpoint publicly","implementation":"Default AUTH_TOKEN to random value or abort startup when missing","expected_gain":"Prevents accidental exposure of DeepSeek API credentials","references":["deepseek_ollama_shim.py"]}
{"rank":16,"category":"dependency","subcategory":"pinning","issue":"requirements.txt and pyproject.toml diverge and omit minimum versions","impact":"MEDIUM","effort":"LOW","file":"requirements.txt","line":1,"current":"numpy (no version constraint)","proposed":"Pin compatible versions and sync with pyproject.toml (use poetry/uv lockfile)","rationale":"Divergent pins cause reproducibility failures across development and CI environments","implementation":"Generate lockfile, update requirements*.txt and pyproject.toml extras to match","expected_gain":"Deterministic builds across CI and developer laptops","references":["pyproject.toml","requirements-dev.txt"]}
{"rank":17,"category":"performance","subcategory":"benchmarking","issue":"benchmark.py assumes live Ollama even in CI sandboxed environments","impact":"MEDIUM","effort":"LOW","file":"benchmark.py","line":33,"current":"if os.environ.get(\"BENCHMARK_FAKE_REMOTE\") == \"1\": ...","proposed":"Default to fake remote unless explicit flag set; skip long benchmarks in CI","rationale":"Current default hits network and fails in sandboxed CI, blocking performance regression detection","implementation":"Flip condition to opt-in for real remote, integrate with pytest-benchmark for CI","expected_gain":"Reliable performance checks without external dependency","references":["scripts/benchmark.sh"]}
{"rank":18,"category":"testing","subcategory":"http","issue":"http_utils._mount_retries lacks direct unit tests for adapter configuration","impact":"MEDIUM","effort":"LOW","file":"clockify_rag/http_utils.py","line":17,"current":"def _mount_retries(sess: requests.Session, retries: int):  # No direct tests","proposed":"Add tests verifying adapter pool sizes and retry settings with urllib3 v1/v2","rationale":"Recent regressions could silently remove retry/backoff behaviour without detection","implementation":"Use requests_mock to inspect mounted adapters in tests/test_http_utils.py","expected_gain":"Ensures reliability of retry/backoff across Python and urllib3 versions","references":["clockify_rag/http_utils.py"]}
{"rank":19,"category":"developer-experience","subcategory":"setup","issue":"setup.sh mixes macOS and Linux package managers with no platform gating","impact":"MEDIUM","effort":"LOW","file":"setup.sh","line":10,"current":"brew install ...; apt-get install ...  # Both run unconditionally","proposed":"Detect platform with uname and run appropriate installer block; warn on unsupported OS","rationale":"Script currently fails midway on any platform due to missing package manager","implementation":"Use case statement on uname -s and provide manual instructions for unsupported systems","expected_gain":"Smoother onboarding and fewer support tickets from failed setup","references":["setup.sh"]}
{"rank":20,"category":"data","subcategory":"artifacts","issue":"chunk_title_map.json is 9530 lines with no documented regeneration process","impact":"LOW","effort":"LOW","file":"chunk_title_map.json","line":1,"current":"Large static JSON file committed to repo","proposed":"Document regeneration process in README; compress/store as gzip to reduce repo bloat","rationale":"Large static file easily drifts from current knowledge base and bloats repository history","implementation":"Add README section, update generate_chunk_title_map.py to write compressed output","expected_gain":"Smaller repo footprint and easier rebuilds after knowledge base updates","references":["scripts/generate_chunk_title_map.py"]}
